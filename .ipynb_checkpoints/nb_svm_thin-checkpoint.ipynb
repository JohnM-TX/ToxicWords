{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "ef06cd19-66b6-46bc-bf45-184e12d3f7d4",
    "_uuid": "cca038ca9424a3f66e10262fc9129de807b5f855"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "# test = pd.read_csv('./input/test.csv')\n",
    "# subm = pd.read_csv('./input/sample_submission.csv')\n",
    "\n",
    "label_cols = list(train)[-6:]\n",
    "cmnt = 'comment_text'\n",
    "\n",
    "train[cmnt].fillna(\"unknown\", inplace=True)\n",
    "# test[cmnt].fillna(\"unknown\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "me_class\n",
       "000000    143346\n",
       "000001        54\n",
       "000010       301\n",
       "000011        28\n",
       "000100        22\n",
       "000110         3\n",
       "001000       317\n",
       "001001         3\n",
       "001010       181\n",
       "001011        18\n",
       "001100         2\n",
       "001110         2\n",
       "100000      5666\n",
       "100001       136\n",
       "100010      1215\n",
       "100011       134\n",
       "100100       113\n",
       "100101         7\n",
       "100110        16\n",
       "100111         3\n",
       "101000      1758\n",
       "101001        35\n",
       "101010      3800\n",
       "101011       618\n",
       "101100        11\n",
       "101110       131\n",
       "101111        56\n",
       "110000        41\n",
       "110001         3\n",
       "110010        14\n",
       "110011         7\n",
       "110100        11\n",
       "110101         2\n",
       "111000       158\n",
       "111001         6\n",
       "111010       989\n",
       "111011       265\n",
       "111100         4\n",
       "111110        64\n",
       "111111        31\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['me_class'] = train[label_cols].apply(lambda x: ''.join(x.map(str)), axis=1)\n",
    "\n",
    "# group the two single classes into one or stratification to wr\n",
    "train.loc[train['me_class']=='110110', 'me_class'] = '110101'\n",
    "# train.groupby('me_class')['id'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31915x426005 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3576947 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(s): \n",
    "    re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "    return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "# get a stratified sample and recombine\n",
    "me_class = train['me_class'].values\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2)\n",
    "for train_index, test_index in sss.split(train, me_class):\n",
    "    train_pc, val = train.iloc[train_index], train.iloc[test_index]\n",
    "train = train_pc.append(val)\n",
    "\n",
    "# make the DTM\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "train_dtm = vec.fit_transform(train[cmnt])\n",
    "# tst_x = vec.transform(test[cmnt])\n",
    "\n",
    "# resplit \n",
    "train_pc_dtm = train_dtm[0:train_pc.shape[0]]\n",
    "val_dtm = train_dtm[-val.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "45fc6070-ba13-455b-9274-5c2611e2809c",
    "_uuid": "8b277f01cecd575ed4fcae2e630c0dd8ce979793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic 100 iterations\n",
      "[LibLinear]fit severe_toxic 250 iterations\n",
      "[LibLinear]fit obscene 200 iterations\n",
      "[LibLinear]fit threat 200 iterations\n",
      "[LibLinear]fit insult 100 iterations\n",
      "[LibLinear]fit identity_hate 100 iterations\n",
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "def pr(y_i, y):\n",
    "    p = trn_x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "def get_mdl(y, iters):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=True, max_iter=iters, verbose=2)\n",
    "    x_nb = train_pc_dtm.multiply(r)\n",
    "    return m.fit(x_nb, y), r\n",
    "\n",
    "iter_list=[100, 250, 200, 200, 100, 100]\n",
    "preds = np.zeros((len(val), len(label_cols)))\n",
    "for c, v in enumerate(label_cols):\n",
    "    print('fit', v, iter_list[c], 'iterations')\n",
    "    m,r = get_mdl(train_pc[v], iter_list[c])\n",
    "    preds[:,c] = m.predict_proba(val_dtm.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "bc6a4575-fbbb-47ea-81ac-91fa702dc194",
    "_uuid": "5dd033a93e6cf32cdbdaa0a8b05cd8d27de2b21d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97525221584780108"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds2 = np.round(preds, decimals=4)\n",
    "preds2 = preds\n",
    "\n",
    "labels = train.iloc[-val.shape[0]: , 2:8]\n",
    "# score\n",
    "roc_auc_score(labels, preds2)\n",
    "\n",
    "\n",
    "# # create submission\n",
    "# submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "# submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "1c345d02-b768-491c-8c03-8c3459a552a8",
    "_uuid": "adbbfb0156952a6a43833e337b8a418ccac257aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99623</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20330</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70235</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "99623       0             0        0       0       0              0\n",
       "154487      0             0        0       0       0              0\n",
       "90          0             0        0       0       0              0\n",
       "20330       0             0        0       0       0              0\n",
       "70235       1             0        0       0       0              0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
