{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%autosave 600\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import Input, Embedding, Dense, Dropout\n",
    "from keras.layers import SpatialDropout1D, Conv1D, Bidirectional, LSTM\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "\n",
    "# from keras import initializers, regularizers, constraints\n",
    "# from keras.layers import , , Activation, \n",
    "# from keras.layers import , GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "# from keras.layers import , BatchNormalization\n",
    "# , load_model\n",
    "# from keras.engine import InputSpec, Layer\n",
    "# from keras.optimizers import Adam, RMSprop\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "# from keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 100000\n",
    "maxlength = 150\n",
    "embed_size = 300\n",
    "\n",
    "embedding_file = \"../vecs/glove.840B.300d.txt\"\n",
    "weights_file = \"./weights/weights_best.hdf5\"\n",
    "sub_file = \"../input/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train)[-6:]\n",
    "y_train = train[class_names].values\n",
    "\n",
    "\n",
    "#preprocess\n",
    "train['comment_text'].fillna(\"no comment\")\n",
    "test['comment_text'].fillna(\"no comment\")\n",
    "\n",
    "x_train0 = train[\"comment_text\"]\n",
    "x_test0 = test[\"comment_text\"]\n",
    "\n",
    "tok = text.Tokenizer(num_words=max_features, lower=True)\n",
    "tok.fit_on_texts(list(x_train0)+list(x_test0))\n",
    "\n",
    "x_train = tok.texts_to_sequences(x_train0)\n",
    "x_test = tok.texts_to_sequences(x_test0)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlength)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_index = {}\n",
    "with open(embedding_file, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs          \n",
    "               \n",
    "\n",
    "word_index = tok.word_index\n",
    "#prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "# x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "# x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool]) \n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "\n",
    "preds = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(lr=0.001),metrics=['accuracy']) # default 0.002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 4\n",
    "x_tra, x_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=233)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "ra_val = RocAucEvaluation(validation_data=(x_val, y_val), interval=1)\n",
    "callbacks_list = [ra_val, checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), \n",
    "          callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "model.load_weights(weights_file)\n",
    "print('Predicting....')\n",
    "y_pred = model.predict(x_test, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.read_csv(sub_file)\n",
    "submission[class_names] = (y_pred)\n",
    "submission.to_csv(\"../subs/sub_bigrucnn.csv\", index = False)\n",
    "\n",
    "print(\"[{}] from Start to Finish.\".format(time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "625px",
    "left": "1361.82px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
