{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n",
      "vectorizing\n",
      "modeling\n",
      "\n",
      "\n",
      "\n",
      " Training on fold 1 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjp914/anaconda3/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          32832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,472,518\n",
      "Trainable params: 472,518\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n",
      "Train on 127641 samples, validate on 31930 samples\n",
      "Epoch 1/1\n",
      "127616/127641 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9802\n",
      " ROC_AUC - epoch 1 - score 0.983822\n",
      "Epoch 00000: val_acc improved from -inf to 0.98241, saving model to ./weights/weights_best_1.hdf5\n",
      "127641/127641 [==============================] - 350s - loss: 0.0558 - acc: 0.9802 - val_loss: 0.0455 - val_acc: 0.9824\n",
      "\n",
      "\n",
      "\n",
      " Training on fold 2 \n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 64)          32832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,472,518\n",
      "Trainable params: 472,518\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n",
      "Train on 127651 samples, validate on 31920 samples\n",
      "Epoch 1/1\n",
      "127616/127651 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9800\n",
      " ROC_AUC - epoch 1 - score 0.984778\n",
      "Epoch 00000: val_acc improved from -inf to 0.98255, saving model to ./weights/weights_best_2.hdf5\n",
      "127651/127651 [==============================] - 362s - loss: 0.0562 - acc: 0.9800 - val_loss: 0.0450 - val_acc: 0.9826\n",
      "\n",
      "\n",
      "\n",
      " Training on fold 3 \n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 64)          32832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,472,518\n",
      "Trainable params: 472,518\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n",
      "Train on 127659 samples, validate on 31912 samples\n",
      "Epoch 1/1\n",
      "127616/127659 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9801\n",
      " ROC_AUC - epoch 1 - score 0.985655\n",
      "Epoch 00000: val_acc improved from -inf to 0.98269, saving model to ./weights/weights_best_3.hdf5\n",
      "127659/127659 [==============================] - 359s - loss: 0.0552 - acc: 0.9801 - val_loss: 0.0461 - val_acc: 0.9827\n",
      "\n",
      "\n",
      "\n",
      " Training on fold 4 \n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 64)          32832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,472,518\n",
      "Trainable params: 472,518\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n",
      "Train on 127665 samples, validate on 31906 samples\n",
      "Epoch 1/1\n",
      "127616/127665 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9802\n",
      " ROC_AUC - epoch 1 - score 0.986185\n",
      "Epoch 00000: val_acc improved from -inf to 0.98309, saving model to ./weights/weights_best_4.hdf5\n",
      "127665/127665 [==============================] - 355s - loss: 0.0557 - acc: 0.9802 - val_loss: 0.0435 - val_acc: 0.9831\n",
      "\n",
      "\n",
      "\n",
      " Training on fold 5 \n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 256)         439296    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 64)          32832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,472,518\n",
      "Trainable params: 472,518\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n",
      "Train on 127668 samples, validate on 31903 samples\n",
      "Epoch 1/1\n",
      "127616/127668 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9806\n",
      " ROC_AUC - epoch 1 - score 0.983000\n",
      "Epoch 00000: val_acc improved from -inf to 0.98361, saving model to ./weights/weights_best_5.hdf5\n",
      "127668/127668 [==============================] - 347s - loss: 0.0540 - acc: 0.9806 - val_loss: 0.0431 - val_acc: 0.9836\n"
     ]
    }
   ],
   "source": [
    "# %load bi_lstm_cv.py\n",
    "\n",
    "%autosave 600\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras import layers as lrs\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "\n",
    "\n",
    "# get data\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "\n",
    "# set vars\n",
    "max_features = 100000\n",
    "maxlength = 150 \n",
    "embed_size = 300\n",
    "\n",
    "\n",
    "# preprocess\n",
    "print('preprocessing')\n",
    "\n",
    "class_names = list(train)[-6:]\n",
    "y_train = train[class_names].values\n",
    "\n",
    "multarray = np.array([100000, 10000, 1000, 100, 10, 1])\n",
    "y_multi = np.sum(train[class_names].values * multarray, axis=1)\n",
    "\n",
    "train['comment_text'].fillna(\"no comment\")\n",
    "test['comment_text'].fillna(\"no comment\")\n",
    "\n",
    "x_train0 = train['comment_text']\n",
    "x_test0 = test['comment_text']\n",
    "\n",
    "toker = text.Tokenizer(num_words=max_features, \n",
    "    filters='?!\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True)\n",
    "toker.fit_on_texts(list(x_train0)+list(x_test0))\n",
    "x_train = toker.texts_to_sequences(x_train0)\n",
    "x_test = toker.texts_to_sequences(x_test0)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlength)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlength)\n",
    "\n",
    "\n",
    "# prepare word vectors/matrix\n",
    "print('vectorizing')\n",
    "\n",
    "embedding_file = \"../vecs/glove.840B.300d.txt\" \n",
    "embeddings_index = {}\n",
    "with open(embedding_file, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs          \n",
    "               \n",
    "word_idx = toker.word_index\n",
    "\n",
    "num_words = min(max_features, len(word_idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in word_idx.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector  # words not found will be all-zeros\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model\n",
    "print('modeling')\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(lrs.Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False))\n",
    "    model.add(lrs.SpatialDropout1D(0.2)) # 0.2\n",
    "    model.add(lrs.Bidirectional(lrs.LSTM(128, return_sequences=True, dropout=0.0, recurrent_dropout=0.0), # 128 0,0 \n",
    "        merge_mode='concat'))          # 'concat' \n",
    "    model.add(lrs.Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"glorot_uniform\"))\n",
    "    model.add(lrs.GlobalMaxPooling1D())    # avg pooling\n",
    "    model.add(lrs.Dense(6, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Nadam(lr=0.001),metrics=['accuracy']) # default 0.002\n",
    "    return model\n",
    "\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.x_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC_AUC - epoch {:d} - score {:.6f}\".format(epoch+1, score))\n",
    "\n",
    "def get_calls(x_val, y_val, weights):\n",
    "    ra_val = RocAucEvaluation(validation_data=(x_val, y_val), interval=1)\n",
    "    checkpoint = ModelCheckpoint(weights, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "    callbacks_list = [ra_val, checkpoint, early]\n",
    "    return callbacks_list\n",
    "\n",
    "def fit_model(x_tra, y_tra, x_val, y_val, weights):\n",
    "    clbks = get_calls(x_val, y_val, weights)\n",
    "    clf = create_model()\n",
    "    clf.fit(x_tra, y_tra, batch_size=128, epochs=1, validation_data=(x_val, y_val),     ### 4-5\n",
    "            callbacks=clbks, verbose=1)\n",
    "    clf.load_weights(weights)\n",
    "    return clf\n",
    "    \n",
    "# do it\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True)                                                  ## 5\n",
    "for i, (train_index, val_index) in enumerate(skf.split(np.zeros(train.shape[0]), y_multi)):\n",
    "    print (\"\\n\\n\\n Training on fold {} \\n\\n\\n\".format(str(i+1)))\n",
    "    xt, xv = x_train[train_index], x_train[val_index]\n",
    "    yt, yv = y_train[train_index], y_train[val_index]\n",
    "    weights_file = \"./weights/weights_best_{}.hdf5\".format(str(i+1))\n",
    "    clfr = fit_model(xt, yt, xv, yv, weights_file)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#cflr.get_weights\n",
    "\n",
    "\n",
    "# # # average all best weights\n",
    "# fold_weight_list = glob('./weights/*.hdf5')\n",
    "\n",
    "# mean_weights = list()\n",
    "\n",
    "# for weights_list_tuple in zip(*weights):\n",
    "#     mean_weights.append(\n",
    "#         [numpy.array(weights_).mean(axis=0)\\\n",
    "#             for weights_ in zip(*weights_list_tuple)])\n",
    "\n",
    "# new_model.set_weights(mean_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test_preds = clfr.predict(x_test, batch_size=1024, verbose=1)\n",
    "\n",
    "# submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "# submission[class_names] = (test_preds)\n",
    "# submission.to_csv(\"../subs/sub_bilstm.csv\", index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = clfr.get_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.get_weights of <keras.models.Sequential object at 0x7f9704554a20>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "441px",
    "left": "1154px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
