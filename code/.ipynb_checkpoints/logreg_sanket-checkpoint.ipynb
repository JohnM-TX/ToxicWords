{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning\n",
      "words\n",
      "chars\n"
     ]
    }
   ],
   "source": [
    "# %load logreg_sanket.py\n",
    "# Sanket Keni \n",
    "'''\n",
    "CV score for class toxic is 0.9758815956729977\n",
    "CV score for class severe_toxic is 0.9885067270242905\n",
    "CV score for class obscene is 0.9919493883065732\n",
    "CV score for class threat is 0.9866684407022007\n",
    "CV score for class insult is 0.9806593278329583\n",
    "CV score for class identity_hate is 0.981040742648163\n",
    "Total CV score is 0.9841177036978639\n",
    "Public LB - 0.9787\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# from playsound import playsound\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from scipy.sparse import hstack\n",
    "import timeit\n",
    "import re\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "############### send notification on smartphone\n",
    "# from urllib.parse import urlencode\n",
    "# from urllib.request import Request, urlopen\n",
    "# url = 'https://www.pushsafer.com/api' # Set destination URL here\n",
    "# post_fields = {                       # Set POST fields here\n",
    "# \t\"t\" : \"Python code execution complete\",\n",
    "# \t\"m\" : \"task finished\" + str(k),\n",
    "# \t\"d\" : \"a\",\n",
    "# \t\"u\" : url,\n",
    "# \t\"k\" : \"*************\"\n",
    "# \t}\n",
    "# def notify():\n",
    "#     request = Request(url, urlencode(post_fields).encode())\n",
    "#     json = urlopen(request).read().decode()\n",
    "#     print(json)\n",
    "\n",
    "\n",
    "# notify when code has completed execution\n",
    "# def audio():\n",
    "#     playsound('C:\\\\Users\\\\Sanket Keni\\\\Music\\\\notification.mp3')\n",
    "\n",
    "\n",
    "train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "'''\n",
    "train['comment_text']=train['comment_text'].apply(lambda x :clean(x))\n",
    "test['comment_text']=test['comment_text'].apply(lambda x :clean(x))\n",
    "'''\n",
    "\n",
    "\n",
    "def cleaned(comment):\n",
    "    comment=comment.lower()\n",
    "    comment=re.sub(\"\\\\n\",\" \",comment)\n",
    "    comment=re.sub(\"\\d{1,}\",\"\",comment)\n",
    "    comment=re.sub(\"\\.{1,}\",\".\",comment)\n",
    "    comment=re.sub(\"\\:{1,}\",\"\",comment)\n",
    "    comment=re.sub(\"\\;|\\=|\\%|\\^|\\_\",\" \",comment)\n",
    "    comment=re.sub(\"\\\"\",\" \",comment)\n",
    "    comment=re.sub(\"\\'{2,}\",\"\",comment)\n",
    "    comment=re.sub(\"\\/|\\!\",\" \",comment)\n",
    "    comment=re.sub(\"\\?\",\" \",comment)\n",
    "    comment=re.sub(\"\\#\",\" \",comment)\n",
    "    comment=re.sub(\"\\,|\\@|\\|\",\" \",comment)\n",
    "    comment=re.sub(\"\\(|\\)\",\" \",comment)\n",
    "    comment=re.sub(\"\\S+jpg\",\" \",comment)\n",
    "    comment=re.sub(\"\\S*wikip\\S+\",\"\",comment)               \n",
    "    comment=re.sub(\"\\[.*?\\]\",\" \",comment)\n",
    "    comment=re.sub(\"\\-\",\" \",comment)\n",
    "    '''comment=re.sub(\"\\\"|:|@|,|\\/|\\=|;|\\.|\\'|\\?|\\!|\\||\\+|\\~|\\-|\\#\",\" \",comment)\n",
    "    comment=re.sub(\"\\.{1,}\",\".\",comment)\n",
    "    comment=re.sub(\"\\[.*?\\]\",\"\",comment)\n",
    "    comment=re.sub(\"www\\S+\",\"\",comment)\n",
    "    comment=re.sub(\"\\_\",\" \",comment)\n",
    "    comment=re.sub(\"http\",\"\",comment)'''\n",
    "    comment=re.sub(r'[^\\x00-\\x7F]+',' ', comment) # remove non ascii\n",
    "    comment=re.sub(\"\\s+\",\" \",comment)\n",
    "    comment = ' '.join( [w for w in comment.split() if len(w)>1])\n",
    "    comment = ' '.join( [stemmer.stem(w) for w in comment.split()])\n",
    "    comment = comment.strip()\n",
    "    return comment\n",
    "\n",
    "print('cleaning')\n",
    "train['comment_text']=train['comment_text'].apply(lambda x :cleaned(x))\n",
    "test['comment_text']=test['comment_text'].apply(lambda x :cleaned(x))\n",
    "# audio()\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "'''\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "mystopwords = \"aa abc\"\n",
    "'''\n",
    "\n",
    "print('words')\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=5000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "#audio()\n",
    "\n",
    "print('chars')\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 3),\n",
    "    max_features=5000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "# audio()\n",
    "\n",
    "train_features = hstack([train_char_features, train_word_features])\n",
    "test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.97588173434854\n",
      "CV score for class severe_toxic is 0.9885067508214161\n",
      "CV score for class obscene is 0.9919493883065732\n",
      "CV score for class threat is 0.9866687169339702\n",
      "CV score for class insult is 0.9806594408147351\n",
      "CV score for class identity_hate is 0.9810405674272298\n",
      "Total CV score is 0.9841177664420774\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "predfile = pd.DataFrame.from_dict({'id': train['id']})\n",
    "\n",
    "for class_name in class_names:\n",
    "    if (class_name in ['toxic']):\n",
    "        train_target = train[class_name]\n",
    "        classifier = LogisticRegression(C=0.63, solver='sag', class_weight = \"balanced\") # sag large datasets and bivariate\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "        cv_preds = cross_val_predict(classifier, train_features, train_target, cv=3, method='predict_proba')\n",
    "        predfile[class_name] = cv_preds[:, 1]\n",
    "        scores.append(cv_score)\n",
    "        print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "        classifier.fit(train_features, train_target)\n",
    "        submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "    elif(class_name in [\"severe_toxic\", \"insult\"]):\n",
    "        train_target = train[class_name]\n",
    "        classifier = LogisticRegression(C=0.38, solver='sag') # sag large datasets and bivariate\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "        cv_preds = cross_val_predict(classifier, train_features, train_target, cv=3, method='predict_proba')\n",
    "        predfile[class_name] = cv_preds[:, 1]\n",
    "        scores.append(cv_score)\n",
    "        print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "        classifier.fit(train_features, train_target)\n",
    "        submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "        \n",
    "    elif(class_name in [\"threat\", \"identity_hate\"]):\n",
    "        train_target = train[class_name]\n",
    "        classifier = LogisticRegression(C=0.45, solver='sag') # sag large datasets and bivariate\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "        cv_preds = cross_val_predict(classifier, train_features, train_target, cv=3, method='predict_proba')\n",
    "        predfile[class_name] = cv_preds[:, 1]\n",
    "        scores.append(cv_score)\n",
    "        print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "        classifier.fit(train_features, train_target)\n",
    "        submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "        \n",
    "    elif(class_name == \"obscene\"):\n",
    "        train_target = train[class_name]\n",
    "        classifier = Ridge(alpha=20, solver='auto',max_iter=100, random_state=22,  tol=0.0005)\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "        cv_preds = cross_val_predict(classifier, train_features, train_target, cv=3)\n",
    "        predfile[class_name] = cv_preds\n",
    "        scores.append(cv_score)\n",
    "        print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "        classifier.fit(train_features, train_target)\n",
    "        submission[class_name] = classifier.predict(test_features)\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "# audio()\n",
    "#notify()\n",
    "predfile.to_csv('../ensembles/preds_logreg_sanket.csv', index=False)\n",
    "submission.to_csv('../ensembles/test_logreg_sanket.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "386px",
    "left": "1130px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
